# -*- coding: utf-8 -*-
"""Trab_sist_inteligentes_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fAnhh1rR5Z06TG06n7Ix0gk6-l3fJfFV
"""

import pandas as pd

"""# Importar os dados"""

df = pd.read_csv("/content/Titanic.csv", sep=",", encoding="ISO-8859-1")

df.info()

"""## Colunas

- `Survived`: 1 se a pessoa sobreviveu;
- `Pclass`: nível do ticket, 1 mais caro, 2 medio, 3 mais barato;
- `SibSp`: número de irmãos/cônjuges no titanic;
- `Parch`: número de pais/filhos no titanic;

## Já é possível perceber que a coluna `Cabin` tem muitos valores nulos e por isso não é muito util na análise.

## A partir das descrições das colunas é possível perceber que as informações contidas em `Pclass` e `Fare` representam a informações similares.
"""

df.head()

"""# Remover colunas que não tem utilidade"""

col_inuteis = ["Name", "Ticket", "Cabin"] # ["Name", "SibSp", "Parch", "Ticket", "Fare", "Cabin", "Embarked"]

df.drop(col_inuteis, axis=1, inplace=True)

df.head()

"""## Reorganizar colunas"""

df = df.loc[:, ["PassengerId", "Sex", "Age", "SibSp", "Parch", "Fare", "Pclass", "Embarked", "Survived"]] # df.loc[:, ["PassengerId", "Sex", "Age", "Pclass", "Survived"]]
df.head()

df.head()

"""# Verificar duplicatas"""

print(f"Número de linhas duplicadas: {df.duplicated().sum()}")

df[df.duplicated()]

"""# Verificar Nulos"""

df.isna().sum()

"""## 86 valores nulos em `Age`

### Média de `Age` por `Survived`
"""

df.groupby("Survived")["Age"].mean()

"""### Média de `Age` por `Pclass`"""

df.groupby("Pclass")["Age"].mean()

"""### Média de `Age` por `Sex`"""

df.groupby("Sex")["Age"].mean()

"""### Média de `Age` por `Survived`, `Sex`, `Pclass`"""

mean_age_df = df.groupby(["Survived", "Sex", "Pclass"])["Age"].mean().reset_index()
mean_age_df

# Renomear a coluna
mean_age_df = mean_age_df.rename(columns={"Age": "GroupAgeMean"})

# Faz o merge dos dois df
df_with_means = df.merge(mean_age_df, on=["Survived", "Sex", "Pclass"], how="left")

# Subsitui valores de `Age` nulos pela média do grupo
df_with_means["Age"] = df_with_means["Age"].fillna(df_with_means["GroupAgeMean"])

# Remover a coluna auxiliar
df = df_with_means.drop(columns="GroupAgeMean")

df.head()

df.dropna(axis=0, subset=["Fare"], inplace=True)

df.isna().sum()

df.groupby("Sex")["Survived"].value_counts()

"""# Encodificação de variáveis"""

df.head()

"""## Dummy"""

atrib_nominais = ["Sex", "Embarked", "Survived"] # ["Sex", "Survived"]

df = pd.get_dummies(df, columns=atrib_nominais)
df.head()

"""## Ordinal"""

atrib_ordinais = ["SibSp", "Parch"] # ["Pclass"]

from sklearn.preprocessing import OrdinalEncoder

df["Pclass"] = df["Pclass"].astype(str)

encoder = OrdinalEncoder(categories=[["3", "2", "1"]])

df[["Pclass"]] = encoder.fit_transform(df[["Pclass"]])

encoder = OrdinalEncoder()

df[atrib_ordinais] = encoder.fit_transform(df[atrib_ordinais])

df.head()

"""# Normalização"""

num_columns = ["Age", "Fare"]

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

df[num_columns] = scaler.fit_transform(df[num_columns])

df.head()

df.set_index("PassengerId", inplace=True)
df.head()

"""# Test"""

import seaborn as sns

sns.heatmap(df.corr(numeric_only=True), annot=True, annot_kws={"size": 6.5}, cmap="rocket")